# Working HuggingFace LLM Configuration
APP_NAME=My LLM Project (HuggingFace)
DEBUG=false
VERSION=0.1.0

# LLM Configuration - Using most reliable free model
MODEL_PROVIDER=huggingface
# MODEL_NAME=distilbert/distilgpt2
# MAX_TOKENS=256
# TEMPERATURE=0.7


MODEL_NAME=distilbert/distilgpt2
MAX_TOKENS=256
TEMPERATURE=0.7

# PDF Processing Settings
PDF_MAX_FILE_SIZE_MB=10
PDF_CHUNK_SIZE=800
PDF_CHUNK_OVERLAP=100


# HuggingFace Configuration  
# Token is optional - leave empty for now, can add later for better performance
HUGGINGFACE_API_TOKEN=
HUGGINGFACE_INFERENCE_API_URL=https://api-inference.huggingface.co/models/
HUGGINGFACE_TASK=text-generation

# Server Configuration
HOST=0.0.0.0
PORT=8000
LOG_LEVEL=INFO

# Alternative models you can try (just change MODEL_NAME):
# MODEL_NAME=openai-community/gpt2                (reliable, good quality)
# MODEL_NAME=microsoft/DialoGPT-small            (fast chat model)  
# MODEL_NAME=microsoft/DialoGPT-medium           (better chat model)
# MODEL_NAME=google/flan-t5-small                (instruction following)